{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIC Virtual Carpentries Workshop - Day 2\n",
    "\n",
    "This lesson is adapted from the [Data Carpentry Ecology lesson](http://www.datacarpentry.org/python-ecology-lesson/)\n",
    "\n",
    "We'll be using the gitter channel to share solutions to challenges, ask questions and chat:\n",
    "\n",
    "**enter link here**\n",
    "\n",
    "\n",
    "## How to use a Jupyter Notebook\n",
    "\n",
    "https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/index.html\n",
    "\n",
    "https://www.packtpub.com/books/content/getting-started-jupyter-notebook-part-1\n",
    "\n",
    "- The file autosaves\n",
    "- You run a cell with **shift + enter** or using the run button in the tool bar\n",
    "- If you run a cell with **option + enter** it will also create a new cell below\n",
    "- See *Help > Keyboard Shortcuts* or the *Cheatsheet* for more info\n",
    "\n",
    "\n",
    "- The notebook has different type of cells: Code and Markdown are most commonly used\n",
    "- **Code** cells expect code for the Kernel you have chosen, syntax highlighting is available, comments in the code are specified with # -> code after this will not be executed\n",
    "- **Markdown** cells allow you to right report style text, using markdown for formatting the style (e.g. Headers, bold face etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading CSV Data Using Pandas\n",
    "\n",
    "We will begin by locating and reading our survey data which are in CSV format.\n",
    "We can use Pandas' `read_csv` function to pull the file directly into a\n",
    "[DataFrame](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if you need to change your directory\n",
    "import os\n",
    "os.getcwd()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not already in the data fodler, change directory\n",
    "os.chdir(\"../data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be careful not tto execute the above cell twice** as it will try to move directory again, but this time from your new location which will give you and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check we are now in the correct folder\n",
    "os.getcwd()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library\n",
    "import pandas as pd\n",
    "#check your version, we need v0.19 or higher\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df = pd.read_csv(\"surveys.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variables we will need later, we originally created them during the previous session\n",
    "avrg_wgt = surveys_df.groupby('plot').mean()['wgt']\n",
    "plot_names = pd.unique(surveys_df['plot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing & Slicing in Python\n",
    "\n",
    "We often want to work with subsets of a **DataFrame** object. There are\n",
    "different ways to accomplish this including: using labels (ie, column headings - as used previously),\n",
    "numeric ranges or specific x,y index locations.\n",
    "\n",
    "## Extracting Range based Subsets: Slicing\n",
    "\n",
    "**REMINDER**: Python Uses 0-based Indexing\n",
    "\n",
    "Let's remind ourselves that Python uses 0-based\n",
    "indexing. This means that the first element in an object is located at position\n",
    "0. This is different from other tools like R and Matlab that index elements\n",
    "within objects starting at 1.\n",
    "\n",
    "\n",
    "![indexing diagram](https://datacarpentry.org/python-ecology-lesson/fig/slicing-indexing.png)\n",
    "\n",
    "![slicing diagram](https://datacarpentry.org/python-ecology-lesson/fig/slicing-slicing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "\n",
    "```python\n",
    "# Create a list of numbers:\n",
    "a = [1,2,3,4,5]\n",
    "```\n",
    "\n",
    "1. What value does the code below return?\n",
    "        a[0]\n",
    "2. How about this:\n",
    "        a[5]\n",
    "3. Or this?\n",
    "        a[len(a)]\n",
    "4. In the example above, calling `a[5]` returns an error. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows in Python\n",
    "\n",
    "Slicing using the `[]` operator selects a set of rows and/or columns from a\n",
    "DataFrame. To slice out a set of rows, you use the following syntax:\n",
    "`data[start:stop]`. When slicing in pandas the start bound is included in the\n",
    "output. The stop bound is one step BEYOND the row you want to select. So if you\n",
    "want to select rows 0, 1 and 2 your code would look like this:\n",
    "\n",
    "```python\n",
    "# select rows 0,1,2 (but not 3)\n",
    "surveys_df[0:3]\n",
    "```\n",
    "\n",
    "The stop bound in Python is different from what you might be used to in\n",
    "languages like Matlab and R.\n",
    "\n",
    "```python\n",
    "# select the first, second and third rows from the surveys variable\n",
    "surveys_df[0:3]\n",
    "# select the first 5 rows (rows 0,1,2,3,4)\n",
    "surveys_df[:5]\n",
    "# select the last element in the list\n",
    "surveys_df[-1:]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reassign values within subsets of our DataFrame. But before we do that, let's make a \n",
    "copy of our DataFrame so as not to modify our original imported data. \n",
    "\n",
    "```python\n",
    "# copy the surveys dataframe so we don't modify the original DataFrame\n",
    "surveys_copy = surveys_df\n",
    "\n",
    "# set the first three rows of data in the DataFrame to 0\n",
    "surveys_copy[0:3] = 0\n",
    "```\n",
    "\n",
    "Next, try the following code: \n",
    "\n",
    "```python\n",
    "surveys_copy.head()\n",
    "surveys_df.head()\n",
    "```\n",
    "What is the difference between the two data frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the surveys dataframe so we don't modify the original DataFrame\n",
    "surveys_copy = surveys_df\n",
    "\n",
    "# set the first three rows of data in the DataFrame to 0\n",
    "surveys_copy[0:3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surveys_copy.head())\n",
    "print(surveys_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencing Objects vs Copying Objects in Python\n",
    "\n",
    "We might have thought that we were creating a fresh copy of the `surveys_df` objects when we \n",
    "used the code `surveys_copy = surveys_df`. However the statement  y = x doesnâ€™t create a copy of our DataFrame. \n",
    "It creates a new variable y that refers to the **same** object x refers to. This means that there is only one object \n",
    "(the DataFrame), and both x and y refer to it. So when we assign the first 3 columns the value of 0 using the \n",
    "`surveys_copy` DataFrame, the `surveys_df` DataFrame is modified too. To create a fresh copy of the `surveys_df`\n",
    "DataFrame we use the syntax y=x.copy(). But before we have to read the surveys_df again because the current version contains the unintentional changes made to the first 3 columns.\n",
    "\n",
    "```python\n",
    "surveys_df = pd.read_csv(\"data/surveys.csv\")\n",
    "surveys_copy= surveys_df.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df = pd.read_csv(\"surveys.csv\")\n",
    "surveys_copy= surveys_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first three rows of data in the DataFrame to 0\n",
    "surveys_copy[0:3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows and Columns in Python Pandas\n",
    "\n",
    "We can select specific ranges of our data in both the row and column directions\n",
    "using either label or integer-based indexing.\n",
    "\n",
    "- `loc`: indexing via *labels* (which can be integers)\n",
    "- `iloc`: indexing via *integers*\n",
    "\n",
    "![loc_iloc_subsetting](http://104.236.88.249/wp-content/uploads/2016/10/Pandas-selections-and-indexing.png)\n",
    "\n",
    "\n",
    "![dataframe_indexing](https://vrzkj25a871bpq7t1ugcgmn9-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/pandas-dataframe-has-indexes.png)\n",
    "\n",
    "To select a subset of rows AND columns from our DataFrame, we can use the `iloc`\n",
    "method. For example, we can select month, day and year (columns 2, 3 and 4 if we\n",
    "start counting at 1), like this:\n",
    "\n",
    "```python\n",
    "surveys_df.iloc[0:3, 1:4]\n",
    "```\n",
    "\n",
    "\n",
    "**Note**: the order of selection is ROW followed by COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.iloc[0:3, 1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we asked for a slice from 0:3. This yielded 3 rows of data. When you\n",
    "ask for 0:3, you are actually telling python to start at index 0 and select rows\n",
    "0, 1, 2 **up to but not including 3**.\n",
    "\n",
    "\n",
    "Let's next explore some other ways to index and select subsets of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns for rows of index values 0 and 10\n",
    "surveys_df.loc[[0, 10], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this do?\n",
    "surveys_df.loc[0:4, 'plot' : 'wgt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when you type the code below?\n",
    "surveys_df.iloc[[0, 10, 45549], :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Labels (.loc) must be found in the DataFrame or you will get a `KeyError`. The same is true for indices (.iloc), you will get an `IndexError` otherwise.\n",
    "\n",
    "When using `loc`, the start bound and the stop bound are **included** and integers\n",
    "*can* be labels (e.g. row numbers), but they refer to the **index label** and not the position. Thus\n",
    "when you use `loc`, and select rowa with index label 1:4, you will get a different result than using `iloc` to select rows 1:4.\n",
    "\n",
    "We can also select a specific data value according to the specific row and\n",
    "column location within the data frame using the `iloc` function:\n",
    "`dat.iloc[row,column]`.\n",
    "\n",
    "\n",
    "```python\n",
    "surveys_df.iloc[2,6]\n",
    "```\n",
    "\n",
    "which gives **output**\n",
    "\n",
    "```\n",
    "'F'\n",
    "```\n",
    "\n",
    "Remember that Python indexing begins at 0. So, the index location [2, 6] selects\n",
    "the element that is 3 rows down and 7 columns over in the DataFrame.\n",
    "\n",
    "## Challenge Activities\n",
    "\n",
    "1. What happens when you type:\n",
    "\t- surveys_df[0:3]\n",
    "\t- surveys_df[:5]\n",
    "\t- surveys_df[-1:]\n",
    "\n",
    "2. What happens when you call:\n",
    "    - `surveys_df.iloc[0:4, 1:4]`\n",
    "    - `surveys_df.loc[0:4, 1:4]`\n",
    "    - How are the two commands different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.iloc[0:4, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.loc[0:4, 1:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Masks\n",
    "\n",
    "A mask can be useful to locate where a particular subset of values exist or\n",
    "don't exist - for example,  NaN, or \"Not a Number\" values. To understand masks,\n",
    "we also need to understand `BOOLEAN` objects in python.\n",
    "\n",
    "Boolean values include `True` or `False`. So for example\n",
    "\n",
    "```python\n",
    "# set x to 5\n",
    "x = 5\n",
    "# what does the code below return?\n",
    "x > 5\n",
    "# how about this?\n",
    "x == 5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful magic to check the variables created throughout this session\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the below double chceck the lists are created during the subsetting section earlier on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# what happens when we ask whether the avrg_wgt list is greater than 2?\n",
    "avrg_wgt > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens when we ask whether the plot_names are greater than 5?\n",
    "plot_names > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ask python what the value of `x > 5` is, we get `False`. This is because x\n",
    "is not greater than 5 it is equal to 5. To create a boolean mask, you first create the\n",
    "True / False criteria (e.g. values > 5 = True). Python will then assess each\n",
    "value in the object to determine whether the value meets the criteria (True) or\n",
    "not (False). Python creates an output object that is the same shape as\n",
    "the original object, but with a True or False value for each index location.\n",
    "\n",
    "\n",
    "### Logical evaluators\n",
    "You can use the syntax below when querying data from a DataFrame. Experiment\n",
    "with selecting various subsets of the \"surveys\" data.\n",
    "\n",
    "* Equals: `==`\n",
    "* Not equals: `!=`\n",
    "* Greater than, less than: `>` or `<`\n",
    "* Greater than or equal to `>=`\n",
    "* Less than or equal to `<=`\n",
    "\n",
    "Let's try this out. Let's identify all locations in the survey data that have\n",
    "null (missing or NaN) data values. We can use the `isnull` method to do this.\n",
    "Each cell with a null value will be assigned a value of  `True` in the new\n",
    "boolean object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.isnull(surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the rows where there are null values,  we can use \n",
    "the mask as an index to subset our data as follows:\n",
    "\n",
    "```python\n",
    "#To select just the rows with NaN values, we can use the .any method\n",
    "surveys_df[pd.isnull(surveys_df).any(axis=1)]\n",
    "```\n",
    "\n",
    "Note that there are many null or NaN values in the `wgt` column of our DataFrame.\n",
    "We will explore different ways of dealing with these in Lesson 03.\n",
    "\n",
    "We can run `isnull` on a particular column too. What does the code below do?\n",
    "\n",
    "```python\n",
    "# what does this do?\n",
    "empty_weights = surveys_df[pd.isnull(surveys_df).any(axis=1)]['wgt']\n",
    "```\n",
    "\n",
    "Let's take a minute to look at the statement above. \n",
    "\n",
    "We are using the Boolean object as an index. \n",
    "We are asking python to select rows that have a `NaN` value\n",
    "for weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We can also select a subset of our data using criteria. For example, we can\n",
    "select all rows that have a year value of 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "surveys_df[surveys_df.year == 2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Or we can select all rows that do not contain the year 2002.\n",
    "surveys_df[surveys_df.year != 2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# We can define sets of criteria too:\n",
    "surveys_df[(surveys_df.year >= 1980) & (surveys_df.year <= 1985)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to extract subsets using multiple criteria is using the .query() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.query(' year >= 1980 & year <= 1985')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Activities\n",
    "\n",
    "1. Select a subset of rows in the `surveys_df` DataFrame that contain data from\n",
    "   the year 1999 and that contain weight values less than or equal to 8. How\n",
    "   many rows did you end up with? What did your neighbor get?\n",
    "2. You can use the `isin` command in python to query a DataFrame based upon a\n",
    "   list of values as follows:\n",
    "   `surveys_df[surveys_df['species'].isin([listGoesHere])]`. Use the `isin` function\n",
    "   to find all plots that contain particular species in\n",
    "   the surveys DataFrame. How many records contain these values?\n",
    "3. Experiment with other queries. Create a query that finds all rows with a weight value > or equal to 0.\n",
    "4. The `~` symbol in Python can be used to return the OPPOSITE of the selection that you specify in python. \n",
    "It is equivalent to **is not in**. Write a query that selects all rows that are NOT equal to 'M' or 'F' in the surveys\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique plot id where species are found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of records where species are found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatinating\n",
    "\n",
    "We can use the `concat` function in Pandas to append either columns or rows from\n",
    "one DataFrame to another.  Let's grab two subsets of our data to see how this\n",
    "works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in first 10 lines of surveys table\n",
    "survey_sub=surveys_df.head(10)\n",
    "survey_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the last 10 rows (minus the last one)\n",
    "survey_sub_last10 = surveys_df[-11:-1]\n",
    "survey_sub_last10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index values to the second dataframe appends properly\n",
    "# drop=True option avoids adding new index column with \n",
    "# old index values\n",
    "survey_sub_last10 = survey_sub_last10.reset_index(drop=True)\n",
    "survey_sub_last10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenate DataFrames, we need to specify the axis. `axis=0` tells\n",
    "Pandas to stack the second DataFrame under the first one. It will automatically\n",
    "detect whether the column names are the same and will stack accordingly.\n",
    "`axis=1` will stack the columns in the second DataFrame to the RIGHT of the\n",
    "first DataFrame. To stack the data vertically, we need to make sure we have the\n",
    "same columns and associated column format in both datasets. When we stack\n",
    "horizonally, we want to make sure what we are doing makes sense (ie the data are\n",
    "related in some way).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([survey_sub, survey_sub_last10], axis = 0)\n",
    "vertical_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the DataFrames side by side\n",
    "horizontal_stack = pd.concat([survey_sub, survey_sub_last10], axis = 1)\n",
    "horizontal_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_stack['wgt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice anything unusual about the `vertical_stack`?\n",
    "\n",
    "The row indexes for the two data frames `survey_sub` and `survey_sub_last10`\n",
    "have been repeated. We can reindex the new dataframe using the `reset_index()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_stack = vertical_stack.reset_index()\n",
    "vertical_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Out Data to CSV\n",
    "\n",
    "We can use the `to_csv` command to do export a DataFrame in CSV format. Note that the code\n",
    "below will by default save the data into the current working directory. We can\n",
    "save it to a different folder by adding the foldername and a slash to the file\n",
    "`vertical_stack.to_csv('foldername/out.csv')`.\n",
    "\n",
    "```python\n",
    "# Write DataFrame to CSV \n",
    "vertical_stack.to_csv('data/out.csv')\n",
    "```\n",
    "\n",
    "Check out your working directory to make sure the CSV wrote out properly, and\n",
    "that you can open it! If you want, try to bring it back into python to make sure\n",
    "it imports properly.\n",
    "\n",
    "```python\t\n",
    "# let's read our output back into python and make sure all looks good\n",
    "new_output = pd.read_csv('data/out.csv', keep_default_na=False, na_values=[\"\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_stack.to_csv('data/out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating data processing using For Loops\n",
    "\n",
    "So far, we've used Python and the pandas library to explore and manipulate\n",
    "individual datasets by hand, much like we would do in a spreadsheet. The beauty\n",
    "of using a programming language like Python, though, comes from the ability to\n",
    "automate data processing through the use of loops and functions.\n",
    "\n",
    "## For loops\n",
    "\n",
    "Loops allow us to repeat a workflow (or series of actions) a given number of\n",
    "times or while some condition is true. We would use a loop to automatically\n",
    "process data that's stored in multiple files (daily values with one file per\n",
    "year, for example). Loops lighten our work load by performing repeated tasks\n",
    "without our direct involvement and make it less likely that we'll introduce\n",
    "errors by making mistakes while processing each file by hand.\n",
    "\n",
    "Let's write a simple for loop that simulates what a kid might see during a\n",
    "visit to the zoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['lion','tiger','crocodile','vulture','hippo']\n",
    "print(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for creature in animals:\n",
    "    print(creature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line defining the loop must start with `for` and end with a colon, and the\n",
    "body of the loop must be indented.\n",
    "\n",
    "In this example, `creature` is the loop variable that takes the value of the next\n",
    "entry in `animals` every time the loop goes around. We can call the loop variable\n",
    "anything we like. After the loop finishes, the loop variable will still exist\n",
    "and will have the value of the last entry in the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(animals[i])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for creature in animals:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not asking python to print the value of the loop variable anymore, but\n",
    "the for loop still runs and the value of `creature` changes on each pass through\n",
    "the loop. The statement `pass` in the body of the loop just means \"do nothing\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The file we've been using so far, `surveys.csv`, contains 25 years of data and is\n",
    "very large. We would like to separate the data for each year into a separate\n",
    "file.\n",
    "\n",
    "Let's start by making a new directory inside the folder `data` to store all of\n",
    "these files using the module `os`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('yearly_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `os.mkdir` is equivalent to `mkdir` in the shell. Just so we are\n",
    "sure, we can check that the new directory was created within the `data` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `os.listdir` is equivalent to `ls` in the shell.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Previously, we saw how to use the library pandas to load the species\n",
    "data into memory as a DataFrame, how to select a subset of the data using some\n",
    "criteria, and how to write the DataFrame into a csv file. Let's write a script\n",
    "that performs those three steps in sequence for the year 2002:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "surveys_df = pd.read_csv('data/surveys.csv')\n",
    "\n",
    "# Select only data for 2002\n",
    "surveys2002 = surveys_df[surveys_df.year == 2002]\n",
    "\n",
    "# Write the new DataFrame to a csv file\n",
    "surveys2002.to_csv('data/yearly_files/surveys2002.csv')\n",
    "```\n",
    "\n",
    "To **create yearly data files**, we could repeat the last two commands over and\n",
    "over, once for each year of data. Repeating code is neither elegant nor\n",
    "practical, and is very likely to introduce errors into your code. **We want to\n",
    "turn what we've just written into a loop** that repeats the last two commands for\n",
    "every year in the dataset.\n",
    "\n",
    "Let's start by writing a loop that simply prints the names of the files we want\n",
    "to create - the dataset we are using covers 1977 through 2002, and we'll create\n",
    "a separate file for each of those years. Listing the filenames is a good way to\n",
    "confirm that the loop is behaving as we expect.\n",
    "\n",
    "\n",
    "We have seen that we can loop over a list of items, so we need a list of years \n",
    "to loop over. We can get the *unique* years in our DataFrame with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this into our for loop we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  year in surveys_df.year.unique():\n",
    "    # creating filename\n",
    "    filename = 'yearly_files/surveys_year' + str(year) + '.csv'\n",
    "    print(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we use single quotes to add text strings. The variable is not\n",
    "surrounded by quotes. This code produces the string\n",
    "`data/yearly_files/surveys_year2002.csv` which contains the path to the new filename\n",
    "AND the file name itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add the rest of the steps we need to create separate text files.\n",
    "Once finished look inside the `yearly_files` directory and check a couple of the files you\n",
    "just created to confirm that everything worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in surveys_df.year.unique():\n",
    "    #creating filename\n",
    "    filename =  'yearly_files/surveys_year' + str(year) + '.csv'\n",
    "    # extracting data of a specific year\n",
    "    surveys_year = surveys_df[surveys_df.year == year]\n",
    "    # writing to file\n",
    "    surveys_year.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('yearly_files/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Challenge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   1. What happens if there is no data for a year in the sequence (for example, imagine we had used 1976 as the start year in range)?\n",
    "\n",
    "   2. Let's say you only want to look at data from a given multiple of years. How would you modify your loop in order to generate a data file for only every 5th year, starting from 1977? Hint: you will need to use range to specify the list of numbers.\n",
    "\n",
    "   ```python\n",
    "range(start, end, steps)\n",
    "```\n",
    "   3. Instead of splitting out the data by years, a colleague wants to do analyses each species separately. How would you write a unique csv file for each species?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do we get returned for a year that does not exist? \n",
    "surveys_df[(surveys_df['year']== 1976)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only save data for every 5th year using range\n",
    "for year in range(surveys_df.year.min(),surveys_df.year.max()+1,5):\n",
    "    #creating filename\n",
    "    filename = 'yearly_files/5yeardata_' + str(year) + '.csv'\n",
    "    # extracting data of a specific year\n",
    "    surveys_year = surveys_df[surveys_df.year == year]\n",
    "    # writing to file\n",
    "    surveys_year.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('yearly_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the unique species\n",
    "surveys_df.species.dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new folder for the species data\n",
    "os.mkdir('species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data files for each species, \n",
    "# Caution: skip the nan\n",
    "for species in surveys_df.species.dropna().unique():\n",
    "    #creating filename\n",
    "    filename = 'species/species_' + species + '.csv'\n",
    "    # extracting data of a specific year\n",
    "    surveys_species = surveys_df[surveys_df.species == species]\n",
    "    # writing to file\n",
    "    surveys_species.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.listdir('species/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building reusable and modular code with functions\n",
    "\n",
    "Suppose that separating large data files into individual yearly files is a task\n",
    "that we frequently have to perform. We could write a **for loop** like the one above\n",
    "every time we needed to do it but that would be time consuming and error prone.\n",
    "A more elegant solution would be to create a reusable tool that performs this\n",
    "task with minimum input from the user. To do this, we are going to turn the code\n",
    "we've already written into a function.\n",
    "\n",
    "Functions are reusable, self-contained pieces of code that are called with a\n",
    "single command. They can be designed to accept arguments as input and return\n",
    "values, but they don't need to do either. Variables declared inside functions\n",
    "only exist while the function is running and if a variable within the function\n",
    "(a local variable) has the same name as a variable somewhere else in the code,\n",
    "the local variable hides but doesn't overwrite the other.\n",
    "\n",
    "Every method used in Python (for example, `print`) is a function, and the\n",
    "libraries we import (say, `pandas`) are a collection of functions. We will only\n",
    "use functions that are housed within the same code that uses them, but it's also\n",
    "easy to write functions that can be used by different programs.\n",
    "\n",
    "Functions are declared following this general structure:\n",
    "\n",
    "```python\n",
    "def this_is_the_function_name(input_argument1, input_argument2):\n",
    "\n",
    "    # The body of the function is indented\n",
    "    # This function prints the two arguments to screen\n",
    "    print('The function arguments are:', input_argument1, input_argument2, '(this is done inside the function!)')\n",
    "\n",
    "    # And returns their product\n",
    "    return input_argument1 * input_argument2\n",
    "```\n",
    "\n",
    "The function declaration starts with the word `def`, followed by the function\n",
    "name and any arguments in parenthesis, and ends in a colon. The body of the\n",
    "function is indented just like loops are. If the function returns something when\n",
    "it is called, it includes a return statement at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's define this function\n",
    "def this_is_the_function_name(input_argument1, input_argument2):\n",
    "\n",
    "    # The body of the function is indented\n",
    "    # This function prints the two arguments to screen\n",
    "    print('The function arguments are:', input_argument1, input_argument2, '(this is done inside the function!)')\n",
    "\n",
    "    # And returns their product\n",
    "    return input_argument1 * input_argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and now let's call the function:\n",
    "this_is_the_function_name(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_is_the_function_name(input_argument2=5, input_argument1=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "\n",
    "1. Try calling the function by giving it the wrong number of arguments (not 2)\n",
    "2. Declare a variable inside the function and test to see where it exists (Hint:\n",
    "   can you print it from outside the function?)\n",
    "3. Explore what happens when a variable both inside and outside the function\n",
    "   have the same name. What happens to the global variable when you change the\n",
    "   value of the local variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try giving only 1 or maybe 3 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_other_function(in1, in2=74646):\n",
    "    new_variable = 3\n",
    "    print(new_variable, in1, in2)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_other_function(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_other_function(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_variable = 5\n",
    "print(new_variable)\n",
    "this_other_function(1,2)\n",
    "print(new_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We can now turn our code for saving yearly data files into a function. There are\n",
    "many different \"chunks\" of this code that we can turn into functions, and we can\n",
    "even create functions that call other functions inside them. Let's first write a\n",
    "function that separates data for just one year and saves that data to a file:\n",
    "\n",
    "```python\n",
    "def one_year_csv_writer(this_year, all_data):\n",
    "    \"\"\"\n",
    "    Writes a csv file for data from a given year.\n",
    "\n",
    "    this_year --- year for which data is extracted\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    \"\"\"\n",
    "\n",
    "    # Select data for the year\n",
    "    surveys_year = all_data[all_data.year == this_year]\n",
    "\n",
    "    # Write the new DataFrame to a csv file\n",
    "    filename = 'data/yearly_files/function_surveys_year' + str(this_year) + '.csv'\n",
    "    surveys_year.to_csv(filename)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_year_csv_writer(this_year, all_data):\n",
    "    \"\"\"\n",
    "    Writes a csv file for data from a given year.\n",
    "\n",
    "    this_year --- year for which data is extracted\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    \"\"\"\n",
    "\n",
    "    # Select data for the year\n",
    "    surveys_year = all_data[all_data.year == this_year]\n",
    "\n",
    "    # Write the new DataFrame to a csv file\n",
    "    filename = 'yearly_files/function_surveys_year' + str(this_year) + '.csv'\n",
    "    surveys_year.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text between the two sets of triple double quotes is called a docstring and\n",
    "contains the documentation for the function. It does nothing when the function\n",
    "is running and is therefore not necessary, but it is good practice to include\n",
    "docstrings as a reminder of what the code does. Docstrings in functions also\n",
    "become part of their 'official' documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find help on inbuilt function sum\n",
    "sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find help on your function one_year_csv_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_csv_writer(2002,surveys_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.listdir('yearly_files/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We changed the root of the name of the csv file so we can distinguish it from\n",
    "the one we wrote before. Check the `yearly_files` directory for the file. Did it\n",
    "do what you expect?\n",
    "\n",
    "---\n",
    "\n",
    "What we really want to do, though, is **create files for multiple years without\n",
    "having to request them one by one**. Let's write another function that replaces\n",
    "the entire `for loop` by simply looping through a sequence of years and repeatedly\n",
    "calling the function we just wrote, `one_year_csv_writer`:\n",
    "\n",
    "\n",
    "```python\n",
    "def yearly_data_csv_writer(start_year, end_year, all_data):\n",
    "    \"\"\"\n",
    "    Writes separate csv files for each year of data.\n",
    "\n",
    "    start_year --- the first year of data we want\n",
    "    end_year --- the last year of data we want\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    \"\"\"\n",
    "\n",
    "    # \"end_year\" is the last year of data we want to pull, so we loop to end_year+1\n",
    "    for year in range(start_year, end_year+1):\n",
    "        one_year_csv_writer(year, all_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_data_csv_writer(start_year, end_year, all_data):\n",
    "    \"\"\"\n",
    "    Writes separate csv files for each year of data.\n",
    "\n",
    "    start_year --- the first year of data we want\n",
    "    end_year --- the last year of data we want\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    \"\"\"\n",
    "\n",
    "    # \"end_year\" is the last year of data we want to pull, so we loop to end_year+1\n",
    "    for year in range(start_year, end_year+1):\n",
    "        one_year_csv_writer(year, all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because people will naturally expect that the end year for the files is the last\n",
    "year with data, the for loop inside the function ends at `end_year + 1`. \n",
    "This is because when we specify `range()` the last number is not included, try it for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By writing the entire loop into a function, we've made a reusable tool for whenever\n",
    "we need to break a large data file into yearly files. Because we can specify the\n",
    "first and last year for which we want files, we can even use this function to\n",
    "create files for a subset of the years available. This is how we call this\n",
    "function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data_csv_writer(1980,1990,surveys_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.listdir('yearly_files/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEWARE!** If you are using IPython Notebooks and you modify a function, you MUST\n",
    "re-run that cell in order for the changed function to be available to the rest\n",
    "of the code. Nothing will visibly happen when you do this, though, because\n",
    "simply defining a function without *calling* it doesn't produce an output. Any\n",
    "cells that use the now-changed functions will also have to be re-run for their\n",
    "output to change.\n",
    "\n",
    "### Challenge:\n",
    "\n",
    "1. **Add two arguments** to the functions we wrote that take the *path* of the\n",
    "   directory where the files will be written and the *root* of the file name.\n",
    "   Additionally, **add default values for all year inputs**. Note, rearrange the order of inputs so that arguments with default are listed last.\n",
    "   Create a new set of files with a different name in a different directory.\n",
    "2. Make the functions **return a list** of the files they have written. There are\n",
    "   many ways you can do this (and you should try them all!): either of the\n",
    "   functions can print to screen, either can use a return statement to give back\n",
    "   numbers or strings to their function call, or you can use some combination of\n",
    "   the two. You could also try using the `os` library to list the contents of\n",
    "   directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding two arguments \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a list of filenames to be returned\n",
    "# adding two arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data_csv_writer(surveys_df, 'yearly_files/','test_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "But what if our dataset doesn't start in 1977 and end in 2002? We can modify the\n",
    "function so that it looks for the start and end years in the dataset if those\n",
    "dates are not provided:\n",
    "\n",
    "```python\n",
    "    def yearly_data_arg_test(all_data, start_year = None, end_year = None):\n",
    "        \"\"\"\n",
    "        Modified from yearly_data_csv_writer to test default argument values!\n",
    "\n",
    "        start_year --- the first year of data we want --- default: None - check all_data\n",
    "        end_year --- the last year of data we want --- default: None - check all_data\n",
    "        all_data --- DataFrame with multi-year data\n",
    "        \"\"\"\n",
    "\n",
    "        if not start_year:\n",
    "            start_year = min(all_data.year)\n",
    "        if not end_year:\n",
    "            end_year = max(all_data.year)\n",
    "\n",
    "        return start_year, end_year\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data_arg_test(surveys_df, 1980, 1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "yearly_data_arg_test(surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default values of the `start_year` and `end_year` arguments in the function\n",
    "`yearly_data_arg_test` are now `None`. This is a build-it constant in Python\n",
    "that indicates the absence of a value - essentially, that the variable exists in\n",
    "the namespace of the function (the directory of variable names) but that it\n",
    "doesn't correspond to any existing object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The body of the test function now has two conditional 'loops' (**if statement**) that\n",
    "check the values of `start_year` and `end_year`. If statements execute the body of\n",
    "the 'loop' when some condition is met. \n",
    "\n",
    "`if statements` work like the boolean logic we saw earlier when we created masks to select our data.\n",
    "As a function they commonly look something like this:\n",
    "\n",
    "```python\n",
    "a = 5\n",
    "\n",
    "if a<0: # meets first condition?\n",
    "\n",
    "    # if a IS less than zero\n",
    "    print('a is a negative number')\n",
    "\n",
    "elif a>0: # did not meet first condition. meets second condition?\n",
    "\n",
    "    # if a ISN'T less than zero and IS more than zero\n",
    "    print('a is a positive number')\n",
    "\n",
    "else: # met neither condition\n",
    "\n",
    "    # if a ISN'T less than zero and ISN'T more than zero\n",
    "    print('a must be zero!')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.0\n",
    "\n",
    "if a<0: # meets first condition?\n",
    "\n",
    "    # if a IS less than zero\n",
    "    print('a is a negative number')\n",
    "\n",
    "elif a>=0: # did not meet first condition. meets second condition?\n",
    "\n",
    "    # if a ISN'T less than zero and IS more than zero\n",
    "    print('a is a positive number')\n",
    "\n",
    "else: # met neither condition\n",
    "\n",
    "    # if a ISN'T less than zero and ISN'T more than zero\n",
    "    print('a must be zero!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of `a` to see how this function works. The statement `elif`\n",
    "means \"else if\", and all of the conditional statements must end in a colon.\n",
    "\n",
    "The if statements in the function `yearly_data_arg_test` check whether there is an\n",
    "object associated with the variable names `start_year` and `end_year`. If those\n",
    "variables are `None`, the if statements return the boolean `True` and execute whatever\n",
    "is in their body. On the other hand, if the variable names are associated with\n",
    "some value (they got a number in the function call), the if statements return `False`\n",
    "and do not execute. The opposite conditional statements, which would return\n",
    "`True` if the variables were associated with objects (if they had received value\n",
    "in the function call), would be `if start_year` and `if end_year`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "\n",
    "1. Rewrite the `one_year_csv_writer` and `yearly_data_csv_writer` functions to use `none` as default for the years.\n",
    "\n",
    "\n",
    "3. The code below checks to see whether a directory exists and creates one if it\n",
    "doesn't. Add some code to your function that writes out the CSV files, to check\n",
    "for a directory to write to.\n",
    "\n",
    "```Python\n",
    "\tif 'dir_name_here' in os.listdir('.'):\n",
    "\t    print('Processed directory exists')\n",
    "\telse:\n",
    "\t    os.mkdir('dir_name_here')\n",
    "\t    print('Processed directory created')\n",
    "```\n",
    "\n",
    "2. Modify the functions so that they don't create yearly files if there is no\n",
    "data for a given year and display an alert to the user (Hint: use conditional\n",
    "statements to do this.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use none as default start/end years\n",
    "# adding a list of filenames to be returned\n",
    "# adding two arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid making a new directory if it exists\n",
    "# use none as default start/end years\n",
    "# adding a list of filenames to be returned\n",
    "# adding two arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't write empty files if there is not data for that year\n",
    "# avoid making a new directory if it exists\n",
    "# use none as default start/end years\n",
    "# adding a list of filenames to be returned\n",
    "# adding two arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_csv_writer(all_data=surveys_df,directory='yearly_files/',file_root='final_test_', this_year=1976)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data_csv_writer(all_data=surveys_df,directory='test_creation/',file_root='final_test_', start_year=1977, end_year=1978)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
