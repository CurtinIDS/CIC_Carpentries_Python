{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91a434d6",
   "metadata": {},
   "source": [
    "# CIDS Carpentries Workshop - Day 1 - Part 4\n",
    "This lesson is adapted from the Data Carpentries [Data Analysis and Visualization in Python for Ecologists](https://datacarpentry.org/python-ecology-lesson/index.html) lesson.\n",
    "\n",
    "---\n",
    "## How to use a Jupyter Notebook\n",
    "Online Resources:\n",
    "- https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/index.html\n",
    "- https://code.visualstudio.com/docs/datascience/jupyter-notebooks \n",
    "\n",
    "Useful Tips:\n",
    "- To save the notebook/file, <kbd>Ctrl</kbd> + <kbd>s</kbd> or Go to `File -> Save`.\n",
    "- You run a cell with <kbd>Shift</kbd> + <kbd>Enter</kbd> or\n",
    "    - **Jupyter Notebook, JupyterLab**: you can use the run button ▶ in the tool bar.\n",
    "    - **VScode**: you can use the run button ▶ in front of the cell.\n",
    "- If you run a cell with <kbd>Option (Alt)</kbd> + <kbd>Enter</kbd> it will also create a new cell below.\n",
    "- If you opened this a classic notebook you can check *Help > Keyboard Shortcuts* else see the *Cheatsheet* for more info.\n",
    "- If you are using VScode, See [Jupyter Notebooks in VS Code](https://code.visualstudio.com/docs/datascience/jupyter-notebooks) for more info.\n",
    "- The notebook has different type of cells (Code and Markdown are most commonly used): \n",
    "    - **Code** cells expect code for the Kernel you have chosen, syntax highlighting is available, comments in the code are specified with `#` -> code after this will not be executed.\n",
    "    - **Markdown** cells allow you to right report style text, using markdown for formatting the style (e.g. Headers, bold face etc).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e997dca9",
   "metadata": {},
   "source": [
    "## ❓Questions and Objectives for this Notebook\n",
    "What should you be able to answer by the end of this notebook?\n",
    "### Questions\n",
    "\n",
    "- What types of data can be contained in a DataFrame?\n",
    "- Why is the data type important?\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Describe how information is stored in a Python DataFrame.\n",
    "- Define the two main types of data in Python: text and numerics.\n",
    "- Examine the structure of a DataFrame.\n",
    "- Modify the format of values in a DataFrame.\n",
    "- Describe how data types impact operations.\n",
    "- Define, manipulate, and interconvert integers and floats in Python.\n",
    "- Analyze datasets having missing/null values (NaN values).\n",
    "- Write manipulated data to a file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d0706",
   "metadata": {},
   "source": [
    "---\n",
    "# Types of Data\n",
    "How information is stored in a DataFrame or a Python object affects what we can do with it and the outputs of calculations as well. There are two main types of data that we will explore in this lesson: numeric and text data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce1b4f",
   "metadata": {},
   "source": [
    "# Numeric Data Types\n",
    "Numeric data types include integers and floats. A **floating point** number (known as a float)  has decimal points even if that decimal point value is 0. For example: 1.13, 2.0, 1234.345. If we have a column that contains both integers and floating point numbers, Pandas will assign the entire column to the float data type so the decimal points are not lost.\n",
    "\n",
    "An **integer** will never have a decimal point. Thus if we wanted to store 1.13 as an integer it would be stored as 1. Similarly, 1234.345 would be stored as 1234. You will often see the data type `Int64` in Python which stands for 64 bit integer. The 64 refers to the memory allocated to store data in each cell which effectively relates to how many digits it can store in each “cell”. Allocating space ahead of time allows computers to optimize storage and processing efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118c524",
   "metadata": {},
   "source": [
    "# Text Data Type\n",
    "The text data type is known as a 'string' in Python, or 'object' in Pandas. Strings can contain numbers and / or characters. For example, a string might be a word, a sentence, or several sentences. A Pandas object might also be a plot name like ‘plot1’. A string can also contain or consist of numbers. For instance, ‘1234’ could be stored as a string, as could ‘10.23’. However **strings that contain numbers can not be used for mathematical operations!**  \n",
    "\n",
    "## Pandas vs Python\n",
    "Pandas and base Python use slightly different names for data types. More on this is in the table below:\n",
    "\n",
    "| Pandas Type  |  Native Python Type  | Description  |\n",
    "|:---:|:---:|:---:|\n",
    "| object  |  \tstring  |  The most general dtype. Will be assigned to your column if column has mixed types (numbers and strings). |\n",
    "|  int64  |  int |  Numeric characters. 64 refers to the memory allocated to hold this character. |\n",
    "|  float64  |  float  |  Numeric characters with decimals. If a column contains numbers and NaNs (see below), pandas will default to float64, in case your missing value has a decimal.  |\n",
    "|  datetime64,  timedelta[ns]  |  N/A (but see the [datetime module](https://docs.python.org/2/library/datetime.html) in Python’s standard library)  | Values meant to hold time data. Look into these for time series experiments.  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add1f857",
   "metadata": {},
   "source": [
    "# Checking the format of our data\n",
    "Now that we’re armed with a basic understanding of numeric and text data types, let’s explore the format of our survey data. We’ll be working with the same surveys.csv dataset that we’ve used in previous lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591b868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure pandas is loaded\n",
    "import pandas as pd\n",
    "\n",
    "# Load data - note that pd.read_csv is used because we imported pandas as pd\n",
    "surveys_df = pd.read_csv('../data/surveys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3f360",
   "metadata": {},
   "source": [
    "Remember that we can check the type of an object like this:  \n",
    "\n",
    "`type(var_name)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6e74fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data type of the data frame we made:\n",
    "type(surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592186c0",
   "metadata": {},
   "source": [
    "Next, let’s look at the structure of our surveys data. In pandas, we can check the type of one column in a DataFrame using the syntax `dataFrameName[column_name].dtype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c8ca34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data type of the column 'sex'\n",
    "surveys_df['sex'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8747dea",
   "metadata": {},
   "source": [
    "A type ‘O’ just stands for “object” which in Pandas’ world is a string (text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4225f107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check the column for 'record_id'\n",
    "surveys_df['record_id'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52810ace",
   "metadata": {},
   "source": [
    "The type `int64` tells us that Python is storing each value within this column as a 64 bit integer.   \n",
    " \n",
    "We can use the `dataframe_name.dtypes` command to view the data type for each column in a DataFrame (all at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20550b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_id          float64\n",
       "month                int64\n",
       "day                  int64\n",
       "year                 int64\n",
       "plot_id              int64\n",
       "species_id          object\n",
       "sex                 object\n",
       "hindfoot_length    float64\n",
       "weight             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveys_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d045e0",
   "metadata": {},
   "source": [
    "Note that most of the columns in our Survey data are of type `int64`. This means that they are 64 bit integers. But the weight column is a floating point value which means it contains decimals. The `species_id` and `sex` columns are objects which means they contain strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4240a",
   "metadata": {},
   "source": [
    "---\n",
    "# Working With Integers and Floats\n",
    "So we’ve learned that computers store numbers in one of two ways: as integers or as floating-point numbers (or floats). Integers are the numbers we usually count with. Floats have fractional parts (decimal places). Let’s next consider how the data type can impact mathematical operations on our data. Addition, subtraction, division and multiplication work on floats and integers as we’d expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a935e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add some things\n",
    "5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb16b7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract some things\n",
    "24-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e78557",
   "metadata": {},
   "source": [
    "If we divide one integer by another, we get a float. The result on Python 3 is different than in Python 2, where the result is an integer (integer division)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5671f23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide two integers\n",
    "5/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788a274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try some different numbers!\n",
    "10/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e96064",
   "metadata": {},
   "source": [
    "We can still use integer division if we want with the `//` operator (two division symbols). This will apply a division, but throw away the remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd3c59c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now try \"Integer\" division\n",
    "10//3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ebf3c",
   "metadata": {},
   "source": [
    "We can also convert a floating point number to an integer or an integer to floating point number. Notice that Python by default rounds down when it converts from floating point to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2158cd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a to an integer\n",
    "a = 7.83\n",
    "int(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4e41fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert b to a float\n",
    "b = 7\n",
    "float(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046edad",
   "metadata": {},
   "source": [
    "---\n",
    "# Working With Our Survey Data\n",
    "Getting back to our data, we can modify the format of values within our data, if we want. For instance, we could convert the record_id field to floating point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c0abe61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the record_id field from an integer to a float\n",
    "surveys_df['record_id'] = surveys_df['record_id'].astype('float64')\n",
    "surveys_df['record_id'].dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae025944",
   "metadata": {},
   "source": [
    "### ✏️ Challenge:\n",
    "Try converting the column plot_id to floats using:  \n",
    "```py\n",
    "surveys_df.plot_id.astype(\"float\")\n",
    "```\n",
    "\n",
    "Then try converting `weight` to an integer. What goes wrong here? What is Pandas telling you? We will talk about some solutions to this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9466e941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2.0\n",
       "1         3.0\n",
       "2         2.0\n",
       "3         7.0\n",
       "4         3.0\n",
       "         ... \n",
       "35544    15.0\n",
       "35545    15.0\n",
       "35546    10.0\n",
       "35547     7.0\n",
       "35548     5.0\n",
       "Name: plot_id, Length: 35549, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveys_df.plot_id.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a94dd26",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/286329i/Library/CloudStorage/OneDrive-Curtin/CIC_Projects/Current/CIC_Carpentries_Python/notebooks/Intro_to_Python_Day1_Pt4.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/286329i/Library/CloudStorage/OneDrive-Curtin/CIC_Projects/Current/CIC_Carpentries_Python/notebooks/Intro_to_Python_Day1_Pt4.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m surveys_df\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mastype(\u001b[39m\"\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/cids-workshop/lib/python3.11/site-packages/pandas/core/generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6530\u001b[0m     results \u001b[39m=\u001b[39m [ser\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy) \u001b[39mfor\u001b[39;00m _, ser \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()]\n\u001b[1;32m   6532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6533\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6534\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   6535\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[1;32m   6536\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/cids-workshop/lib/python3.11/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    415\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    416\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    417\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    418\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    419\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[1;32m    420\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/cids-workshop/lib/python3.11/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/mambaforge/envs/cids-workshop/lib/python3.11/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m    618\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/cids-workshop/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/cids-workshop/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    185\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/mambaforge/envs/cids-workshop/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mensure_string_array(\n\u001b[1;32m     97\u001b[0m         arr, skipna\u001b[39m=\u001b[39mskipna, convert_na_value\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     )\u001b[39m.\u001b[39mreshape(shape)\n\u001b[1;32m    100\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mand\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39miu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m _astype_float_to_int_nansafe(arr, dtype, copy)\n\u001b[1;32m    103\u001b[0m \u001b[39melif\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[39m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39mis_np_dtype(dtype, \u001b[39m\"\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/mambaforge/envs/cids-workshop/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:146\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(values)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    147\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    150\u001b[0m     \u001b[39m# GH#45151\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (values \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "surveys_df.weight.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a871a9",
   "metadata": {},
   "source": [
    "# Missing Data Values - NaN\n",
    "What happened in the last challenge activity? Notice that this throws one of the following errors: `ValueError: Cannot convert NA to integer` or `IntCastingNaNError: Cannot convert non-finite values (NA or inf) to integer`. If we look at the weight column in the surveys data we notice that there are NaN (**N**ot **a** **N**umber) values. NaN values are undefined values that cannot be represented mathematically. Pandas, for example, will read an empty cell in a CSV or Excel sheet as a NaN. NaNs have some desirable properties: if we were to average the weight column without replacing our NaNs, Python would know to skip over those cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "419b7e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.672428212991356"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the weight column\n",
    "surveys_df['weight'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fcfcd9",
   "metadata": {},
   "source": [
    "Dealing with missing data values is always a challenge. It’s sometimes hard to know why values are missing - was it because of a data entry error? Or data that someone was unable to collect? Should the value be 0? We need to know how missing values are represented in the dataset in order to make good decisions. If we’re lucky, we have some metadata that will tell us more about how null values were handled.\n",
    "\n",
    "For instance, in some disciplines, like Remote Sensing, missing data values are often defined as -9999 or -999. Having a bunch of -9999 values in your data could really alter numeric calculations. Often in spreadsheets, cells are left empty where no data are available. Pandas will, by default, replace those missing values with NaN. However it is good practice to get in the habit of intentionally marking cells that have no data, with a no data value! That way there are no questions in the future when you (or someone else) explores your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca6b30",
   "metadata": {},
   "source": [
    "# Where Are the NaN’s?\n",
    "Let’s explore the NaN values in our data a bit further. Using the tools we learned in lesson 02 (from yesterday!), we can figure out how many rows contain NaN values for weight. We can also create a new subset from our data that only contains rows with weight values > 0 (i.e., select meaningful weight values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecd8b007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32283"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows have weight values?\n",
    "len(surveys_df[surveys_df['weight'].notnull()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7984f075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3266"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows have null values?\n",
    "len(surveys_df[surveys_df['weight'].isnull()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d0800",
   "metadata": {},
   "source": [
    "We can replace all `NaN` values with zeroes using the `.fillna()` method (after making a copy of the data so we don’t lose our work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03d47c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy! Be sure to assign a new variable using the \".copy()\" method!\n",
    "df1 =surveys_df.copy()\n",
    "# Now fill all NaN values with 0\n",
    "df1['weight'] = df1['weight'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e3ff2",
   "metadata": {},
   "source": [
    "However `NaN` and 0 yield different analysis results. The mean value when `NaN` values are replaced with 0 is different from when `NaN` values are simply thrown out or ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb225e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.751976145601844"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the mean of df1\n",
    "df1['weight'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d641704b",
   "metadata": {},
   "source": [
    "We can fill `NaN` values with any value that we chose. The code below fills all `NaN` values with a mean for all weight values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65ca4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['weight'] = surveys_df['weight'].fillna(surveys_df['weight'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1daf80",
   "metadata": {},
   "source": [
    "We could also chose to create a subset of our data, only keeping rows that do not contain NaN values.\n",
    "\n",
    "The point is to **make conscious decisions about how to manage missing data**. This is where we think about how our data will be used and how these values will impact the scientific conclusions made from the data.\n",
    "\n",
    "Python gives us all of the tools that we need to account for these issues. We just need to be cautious about how the decisions that we make impact scientific results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49613333",
   "metadata": {},
   "source": [
    "### ✏️ Challenge - Counting\n",
    "Count the number of missing values per column of the original dataframe `surveys_df`\n",
    "\n",
    "Hints:  \n",
    "As with almost everything programming, there are multiple ways to do this.  \n",
    "  Try the method `.count()`, which gives you the number of non-NA observations per column (we need the NA observations per column).  \n",
    "  \n",
    "You could also try using the `.isnull()` or `.isna()` methods too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5982534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record_id 0\n",
      "month 0\n",
      "day 0\n",
      "year 0\n",
      "plot_id 0\n",
      "species_id 763\n",
      "sex 2511\n",
      "hindfoot_length 4111\n",
      "weight 3266\n"
     ]
    }
   ],
   "source": [
    "for column in surveys_df.columns:\n",
    "    print(column, len((surveys_df[surveys_df[column].isna()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9766e099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record_id 0\n",
      "month 0\n",
      "day 0\n",
      "year 0\n",
      "plot_id 0\n",
      "species_id 763\n",
      "sex 2511\n",
      "hindfoot_length 4111\n",
      "weight 3266\n"
     ]
    }
   ],
   "source": [
    "for column in surveys_df.columns:\n",
    "    print(column, len(surveys_df[pd.isnull(surveys_df[column])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f98cb",
   "metadata": {},
   "source": [
    "# Writing Out Data to CSV\n",
    "We’ve learned about using manipulating data to get desired outputs. But we’ve also discussed keeping data that has been manipulated separate from our raw data. Something we might be interested in doing is working with only the columns that have full data. First, let’s reload the data so we’re not mixing up all of our previous manipulations.  \n",
    "We do this with:  \n",
    "`pd.read_csv(\"file location\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa68bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data in again and store it in memory\n",
    "surveys_df = pd.read_csv('../data/surveys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490e706",
   "metadata": {},
   "source": [
    "Next, let’s drop all the rows that contain missing values. We will use the method `dropna()`. By default, `dropna()` removes rows that contain missing data for even just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f96be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new dataframe \n",
    "df_na = surveys_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2d882",
   "metadata": {},
   "source": [
    "If you now type `df_na`, you should observe that the resulting DataFrame has 30676 rows and 9 columns, much smaller than the 35549 row original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c254b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>37.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>4</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>4</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35540</th>\n",
       "      <td>35541</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>PB</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35541</th>\n",
       "      <td>35542</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>PB</td>\n",
       "      <td>F</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35542</th>\n",
       "      <td>35543</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>PB</td>\n",
       "      <td>F</td>\n",
       "      <td>27.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35546</th>\n",
       "      <td>35547</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>RM</td>\n",
       "      <td>F</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35547</th>\n",
       "      <td>35548</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>DO</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30676 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       record_id  month  day  year  plot_id species_id sex  hindfoot_length  \\\n",
       "62            63      8   19  1977        3         DM   M             35.0   \n",
       "63            64      8   19  1977        7         DM   M             37.0   \n",
       "64            65      8   19  1977        4         DM   F             34.0   \n",
       "65            66      8   19  1977        4         DM   F             35.0   \n",
       "66            67      8   19  1977        7         DM   M             35.0   \n",
       "...          ...    ...  ...   ...      ...        ...  ..              ...   \n",
       "35540      35541     12   31  2002       15         PB   F             24.0   \n",
       "35541      35542     12   31  2002       15         PB   F             26.0   \n",
       "35542      35543     12   31  2002       15         PB   F             27.0   \n",
       "35546      35547     12   31  2002       10         RM   F             15.0   \n",
       "35547      35548     12   31  2002        7         DO   M             36.0   \n",
       "\n",
       "       weight  \n",
       "62       40.0  \n",
       "63       48.0  \n",
       "64       29.0  \n",
       "65       46.0  \n",
       "66       36.0  \n",
       "...       ...  \n",
       "35540    31.0  \n",
       "35541    29.0  \n",
       "35542    34.0  \n",
       "35546    14.0  \n",
       "35547    51.0  \n",
       "\n",
       "[30676 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a94588",
   "metadata": {},
   "source": [
    "We can now use the `to_csv()` method to export a DataFrame in CSV format. Note that the code below will by default save the data into the current working directory. We can save it to a different folder by adding the foldername and a slash before the filename: `df.to_csv('foldername/out.csv')`. We use `index=False` so that pandas doesn’t include the index number for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14f17951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to CSV file '../data_output/surveys_complete.csv'\n",
    "df_na.to_csv('../data/surveys_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be8c87",
   "metadata": {},
   "source": [
    "We will use this data file later in the workshop. Check out your working directory to make sure the CSV wrote out properly, and that you can open it! If you want, try to bring it back into Python to make sure it imports properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7023ecd",
   "metadata": {},
   "source": [
    "---\n",
    "# Recap\n",
    "What we’ve learned:\n",
    "- How to explore the data types of columns within a DataFrame\n",
    "- How to change the data type\n",
    "- What NaN values are, how they might be represented, and what this means for your work\n",
    "- How to replace NaN values, if desired\n",
    "- How to use to_csv to write manipulated data to a file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcc314",
   "metadata": {},
   "source": [
    "# ❗Key Points\n",
    "\n",
    "\n",
    "- Pandas uses other names for data types than Python, for example: object for textual data.\n",
    "- A column in a DataFrame can only have one data type.\n",
    "- The data type in a DataFrame’s single column can be checked using dtype.\n",
    "- Make conscious decisions about how to manage missing data.\n",
    "- A DataFrame can be saved to a CSV file using the to_csv function.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
