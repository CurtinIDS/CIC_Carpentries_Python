{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIC Carpentries Workshop - Day 1 - Part 2\n",
    "This lesson is adapted from the Data Carpentries [Data Analysis and Visualization in Python for Ecologists](https://datacarpentry.org/python-ecology-lesson/index.html) lesson.\n",
    "\n",
    "---\n",
    "## How to use a Jupyter Notebook\n",
    "Online Resources:\n",
    "- https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/index.html\n",
    "- https://www.packtpub.com/books/content/getting-started-jupyter-notebook-part-1\n",
    "\n",
    "Useful Tips:\n",
    "- The notebook autosaves\n",
    "- You run a cell with **shift + enter** or using the run button in the tool bar\n",
    "- If you run a cell with **option + enter** it will also create a new cell below\n",
    "- See *Help > Keyboard Shortcuts* or the *Cheatsheet* for more info\n",
    "- The notebook has different type of cells (Code and Markdown are most commonly used): \n",
    "    - **Code** cells expect code for the Kernel you have chosen, syntax highlighting is available, comments in the code are specified with # -> code after this will not be executed\n",
    "    - **Markdown** cells allow you to right report style text, using markdown for formatting the style (e.g. Headers, bold face etc)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with Data\n",
    "\n",
    "### Working with Pandas DataFrames in Python\n",
    "We can automate the process of performing data manipulations in Python. It's efficient to spend time building the code to perform these tasks because once it's built, we can use it over and over on different datasets that use a similar format. This makes our methods easily reproducible. We can also easily share our code with colleagues and they can replicate the same analysis.\n",
    "\n",
    "#### Starting in the same spot\n",
    "To help the lesson run smoothly, let's ensure that everyone is in the same directory. This should help us avoid path and filename issues. At this time, please navigate to the workshop directory. If you are working in Jupyter Notebook, be sure that you start your notebook in the workshop directory.\n",
    "\n",
    "A quick aside is that there are Python libraries like [OS\n",
    "Library](https://docs.python.org/3/library/os.html) and [pathlib](https://docs.python.org/3/library/pathlib.html) that can work with our\n",
    "directory structure, however, that is not our focus today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Data\n",
    "For this lesson, we will be using the Portal Teaching data, a subset of the data\n",
    "from Ernst et al\n",
    "[Long-term monitoring and experimental manipulation of a Chihuahuan Desert ecosystem near Portal, Arizona, USA](http://www.esapubs.org/archive/ecol/E090/118/default.htm)\n",
    "\n",
    "We will be using files from the [Portal Project Teaching Database](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459).\n",
    "This section will use the `surveys.csv` file which can be found in ../data/.\n",
    "\n",
    "We are studying the species and weight of animals caught in plots in our study\n",
    "area. The dataset is stored as a `.csv` file: each row holds information for a\n",
    "single animal, and the columns represent:\n",
    "\n",
    "| Column           | Description                        |\n",
    "|------------------|------------------------------------|\n",
    "| record_id        | Unique id for the observation      |\n",
    "| month            | month of observation               |\n",
    "| day              | day of observation                 |\n",
    "| year             | year of observation                |\n",
    "| plot             | ID of a particular plot            |\n",
    "| species          | 2-letter code                      |\n",
    "| sex              | sex of animal (\"M\", \"F\")           |\n",
    "| wgt              | weight of the animal in grams      |\n",
    "\n",
    "\n",
    "The first few rows of our first file look like this:\n",
    "\n",
    "```\n",
    "record_id,month,day,year,plot_id,species_id,sex,hindfoot_length,weight\n",
    "1,7,16,1977,2,NL,M,32,\n",
    "2,7,16,1977,3,NL,M,33,\n",
    "3,7,16,1977,2,DM,F,37,\n",
    "4,7,16,1977,7,DM,M,36,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About Libraries\n",
    "![](package.png)\n",
    "\n",
    "A library in Python contains a set of tools (called functions) that perform\n",
    "tasks on our data. Importing a library is like getting a piece of lab equipment\n",
    "out of a storage locker and setting it up on the bench for use in a project.\n",
    "Once a library is set up, it can be used or called to perform many tasks.\n",
    "\n",
    "You only need to load a library once during your session. You can load the library when needed\n",
    "or you can load all necessary libraries at the beginning of your script. \n",
    "This is good practice, especially for the readability of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas in Python\n",
    "One of the best options for working with tabular data in Python is to use the\n",
    "[Python Data Analysis Library](http://pandas.pydata.org/) (a.k.a. Pandas). The\n",
    "Pandas library provides data structures, produces high quality plots with\n",
    "[matplotlib](http://matplotlib.org/) and integrates nicely with other libraries\n",
    "that use [NumPy](http://www.numpy.org/) (which is another Python library) arrays.\n",
    "\n",
    "Python doesn't load all of the libraries available to it by default. We have to\n",
    "add an `import` statement to our code in order to use library functions. To import\n",
    "a library, we use the syntax `import libraryName`. If we want to give the\n",
    "library a nickname to shorten the command, we can add `as nickNameHere`.  An\n",
    "example of importing the pandas library using the common nickname `pd` is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we call a function that's in a library, we use the syntax\n",
    "`LibraryName.FunctionName`. Adding the library name with a `.` before the\n",
    "function name tells Python where to find the function. In the example above, we\n",
    "have imported Pandas as `pd`. This means we don't have to type out `pandas` each\n",
    "time we call a Pandas function.\n",
    "\n",
    "A handy **Pandas cheatsheet** can be found [here](http://pandas.pydata.org/Pandas_Cheat_Sheet.pdf).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV Data using Pandas\n",
    "We will begin by locating and reading our survey data which is in CSV format. We can use Pandas' `read_csv` function to pull the file directly into a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html#dataframe).\n",
    "\n",
    "#### So What's a DataFrame?\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, factors and more) in columns. It is similar to a spreadsheet or an SQL table or the `data.frame` in R. A DataFrame always has an index (0-based). An index refers to the position of an element in the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that pd.read_csv is used because we imported pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there were 35,549 rows parsed. Each row has 9 columns. The first column is the index of the DataFrame. The index is used to identify the position of the data, but it is not an actual column of the DataFrame. It looks like the `read_csv` function in Pandas read our file properly. However, we haven’t saved any data to memory so we can work with it. We need to assign the DataFrame to a variable. Remember that a variable is a name for a value, such as `x`, or `data`. We can create a new object with a variable name by assigning a value to it using `=`.\n",
    "\n",
    "Let’s call the imported survey data `surveys_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice when you assign the imported DataFrame to a variable, Python does not produce any output on the screen. We can view the value of the `surveys_df` object by typing its name into the Python command prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Our Species Survey Data\n",
    "Now, we can start exploring our data. First, let's check the data type of the data stored in `surveys_df` using the `type` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of things does `surveys_df` contain? DataFrames conveniently has an attribute called `dtypes` which answers this by returning the data type for each column in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the values in a column have the same data type. \n",
    "\n",
    "Recalling from the previous episode about Python data types. Pandas and base Python use slightly different names for data types.\n",
    "\n",
    "| Pandas Type | Native Python Type | Description |\n",
    "|-------------|--------------------|-------------|\n",
    "| object | string | The most general dtype. Will be assigned to your column if column has mixed types (numbers and strings). |\n",
    "| int64  | int | Numeric characters. 64 refers to the memory allocated to hold this character. |\n",
    "| float64 | float | Numeric characters with decimals. If a column contains numbers and NaNs(see below), pandas will default to float64, in case your missing value has a decimal. |\n",
    "| datetime64, timedelta[ns] | N/A (but see the [datetime](http://doc.python.org/2/library/datetime.html) module in Python's standard library) | Values meant to hold time data. Look into these for time series experiments. |\n",
    "\n",
    "For example, months have type `int64`, which is an integer. Weight and hindfoot_length have type `float64` which is a floating point value. The `object` type in species_id and sex doesn't have a very helpful name, but in this case it represents strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful Ways to View DataFrame Objects in Python\n",
    "There are many ways to summarise and access the data stored in DataFrames, using attributes and methods provided by the DataFrame object.\n",
    "\n",
    "Let's try out a few.\n",
    "\n",
    "To access an attribute, use the DataFrame object name followed by the attribute `df_object.attribute`. Using the DataFrame `surveys_df` and attribute `columns`, an index of all the column names in the DataFrame can be access with `surveys_df.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods are called in a similar fashion using the syntax `df_object.method()`. As an example, `surveys_df.head()` gets the first few rows in the DataFrame `surveys_df` using **the `head()` method**. With a method, we can supply extra information in the parenthesis to control behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge\n",
    "Using our DataFrame `surveys_df`, try out the attributes and methods to see what they return.\n",
    "1. `surveys_df.shape` - take a note of the output of `shape` - what format does it return the shape of the DataFrame in?\n",
    "2. `surveys_df.head(15)`\n",
    "3. `surveys_df.tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Statistics from Data in a Pandas DataFrame\n",
    "We've now read our data into Python. Next, let's perform some quick summary statistics to learn more about the data that we're working with. We might want to know how many animals were collected in each site, or how many of each species were caught. We can perform summary stats quickly using groups. But first, we need to figure out what we want to group by.\n",
    "\n",
    "Let's explore our data some further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the column names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a list of all the species. The `pd.unique` function tells us all of the unique values in the `species_id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the unique species ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can do this, let's create a list of unique site IDs (`plot_id`) found in the survey data. Call it `site_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique site ids list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique sites are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single line solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe in Pandas\n",
    "We can calculate basic statistics for all records in a single column using the Pandas `describe` function which will return descriptive stats including: mean, median, max, min, std, and count for a particular column in the data. However, it will only return summary values for columns containing numeric data.\n",
    "\n",
    "For example, we might want to calculate the average weight of all individuals per site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the entire dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the weight column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract one specific metric if we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groups in Pandas\n",
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data however. For example, we want to know what the summary statistics look like split by `sex`. We can use Pandas' `.groupby` method, which creates a groupby DataFrame on which we can perform other Pandas methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping surveys_df by sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the new df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the mean for each numeric column by sex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupby` function is powerful in that it allows us to quickly generate summary stats, not just for one group, but several.\n",
    "\n",
    "For example, we might want to calculate the average weight of individuals per plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average weight of all individuals per plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we might want to know how many males and females we have at each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of each sex per site\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Math Functions in Pandas\n",
    "If we wanted to, we could perform math on an entire column of our data. For example, let's multiply all weight values by 2.\n",
    "\n",
    "A more practical use of this might be the normalise the data according to mean, area, or some other value calculated from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply all weight values by 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick & Easy Plotting Data Using Pandas\n",
    "We can plot our summary stats using Pandas too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot year vs weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quick bar chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at how many animals were captured in each site\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge\n",
    "These challenge activities involve plotting data. It's often best to create an object to plot first, then call the .plot() method on it (see the skeleton code below with 'avrg_wgt')\n",
    "1. Create a scatter plot of average weight across all species per plot.  \n",
    " - The final plots x-axis should be 'plot', and the y axis should be 'wgt'.  \n",
    " - If you use `avrg_wgt.plot()`, you will by default get a **line** plot. To turn this into a scatter plot, add the    <u>optional</u> **keyword argument** (aka \"**kwarg**\") `style='o'` to plot arguments:\n",
    "    ```\n",
    "    avrg_wgt.plot(style='o')\n",
    "    ```\n",
    " - If you're missing a label, try adding the **kwarg** xlabel or ylabel to the argument of plot, separated by commas:\n",
    "   ```\n",
    "   avrg_wgt.plot(xlabel='your_x_label', ylabel='your_y_label')\n",
    "   ```\n",
    "2. Create the same plot, but with average weight for each sex per plot. Hint, you will need to `unstack` when plotting. x-axis = plot, y-axis = wgt, different lines for each sex. This is done for you in the skeleton code provided.\n",
    "\n",
    "3. Create a trend plot of the average weight per plot over time. x-axis = year, y-axis = wgt, different lines for each plot.\n",
    " - Extra challenge question: Why do you need to unstack for q2 and a3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by plot_id and calculate mean weight\n",
    "avrg_wgt = surveys_df.groupby('plot_id').mean()['weight']\n",
    "\n",
    "# Let's plot, you should see x-axis -> plot_id, y-axis -> weight\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by plot_id and sex, then calculate mean weight\n",
    "avrg_wgt = surveys_df.groupby(['plot_id', 'sex']).mean()['weight']\n",
    "\n",
    "# Let's plot, you should see x-axis -> plot_id, y-axis -> weight, different lines for sex\n",
    "# You need to use the .unstack() method before the .plot() for this to work\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by year and plot_id, then calculate mean weight\n",
    "# wgt_by_time = surveys_df.groupby(['year', 'plot_id']).mean()['weight']\n",
    "\n",
    "# Let's plot, you should see x-axis -> year, y-axis -> weight, different lines for plot\n",
    "# You need to use the .unstack() method before the .plot() for this to work\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cic-workshop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "898930c4a353cd4bdff091a46da5cc4a2ffb7f83893d6981c0c4cfa6b3e92a4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
