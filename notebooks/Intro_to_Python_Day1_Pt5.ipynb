{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09120bc3",
   "metadata": {},
   "source": [
    "# CIC Carpentries Workshop - Day 1 - Part 5\n",
    "This lesson is adapted from the Data Carpentries [Data Analysis and Visualization in Python for Ecologists](https://datacarpentry.org/python-ecology-lesson/index.html) lesson.\n",
    "\n",
    "---\n",
    "## How to use a Jupyter Notebook\n",
    "Online Resources:\n",
    "- https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/index.html\n",
    "- https://www.packtpub.com/books/content/getting-started-jupyter-notebook-part-1\n",
    "\n",
    "Useful Tips:\n",
    "- The notebook autosaves\n",
    "- You run a cell with **shift + enter** or using the run button in the tool bar\n",
    "- If you run a cell with **option + enter** it will also create a new cell below\n",
    "- See *Help > Keyboard Shortcuts* or the *Cheatsheet* for more info\n",
    "- The notebook has different type of cells (Code and Markdown are most commonly used): \n",
    "    - **Code** cells expect code for the Kernel you have chosen, syntax highlighting is available, comments in the code are specified with # -> code after this will not be executed\n",
    "    - **Markdown** cells allow you to right report style text, using markdown for formatting the style (e.g. Headers, bold face etc)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830ed89",
   "metadata": {},
   "source": [
    "## ❓Questions and Objectives for this Notebook\n",
    "What should you be able to answer by the end of this notebook?\n",
    "\n",
    "### Questions\n",
    "\n",
    "- How can I work with data from multiple sources?\n",
    "- How can I combine data from different data sets?\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Combine data from multiple files into a single DataFrame using merge and concat.\n",
    "- Combine two DataFrames using a unique ID found in both DataFrames.\n",
    "- Employ to_csv to export a DataFrame in CSV format.\n",
    "- Join DataFrames using common fields (join keys).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b54a7",
   "metadata": {},
   "source": [
    "In many “real world” situations, the data that we want to use come in multiple files. We often need to combine these files into a single DataFrame to analyze the data. The pandas package provides [various methods for combining DataFrames](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) including `merge` and `concat`.\n",
    "\n",
    "To work through the examples below, we first need to load both the **species** and **surveys** files into pandas DataFrames as we have done in previous notebooks.  \n",
    "\n",
    "This time however, we will use the **keyword arguments** `keep_default_na=False` with `na_values=[\"\"]` , which will be explained shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "\n",
    "# load the \"data/surveys.csv\" dataframe into a python variable\n",
    "\n",
    "# print the data frame below to check the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a722648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the \"data/species.csv\" dataframe into a different python variable\n",
    "\n",
    "# print the data frame below to check the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d155af11",
   "metadata": {},
   "source": [
    "As mentioned, take note that the `read_csv` method we used can take some additional options which we didn’t use previously. Many functions in Python have a set of options that can be set by the user if needed. In this case, we have told pandas to not assign NaN values with its default settings, but to then assign only empty values in our CSV to NaN: `keep_default_na=False, na_values=[\"\"]`. More about all of the `read_csv` options [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv).  \n",
    "\n",
    "If you ever have a method you're not sure how to use, or want to use in a particular way, a quick web search can often give you the answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fe138",
   "metadata": {},
   "source": [
    "# Concatenating DataFrames\n",
    "We can use the concat function in pandas to append either columns or rows from one DataFrame to another. Let’s grab two subsets of our data to see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in first 10 lines of surveys table\n",
    "\n",
    "# Grab the last 10 rows\n",
    "\n",
    "# Reset the index values to the second dataframe appends properly\n",
    "# We use the keyword drop=True here to avoid adding new index columns with old index values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfcc568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8326b3",
   "metadata": {},
   "source": [
    "When we concatenate DataFrames, we need to specify the axis. `axis=0` tells pandas to stack the second DataFrame UNDER the first one. It will automatically detect whether the column names are the same and will stack accordingly. `axis=1` will stack the columns in the second DataFrame to the RIGHT of the first DataFrame. To stack the data vertically, we need to make sure we have the same columns and associated column format in both datasets. When we stack horizontally, we want to make sure what we are doing makes sense (i.e. the data are related in some way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the DataFrames on top of each other\n",
    "\n",
    "# Place the DataFrames side by side\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efab274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ae3d7",
   "metadata": {},
   "source": [
    "# Row Index Values and Concat\n",
    "\n",
    "Had a look at the `vertical_stack` dataframe? Notice anything unusual? The row indexes for the two data frames `survey_sub` and `survey_sub_last10` have been repeated. We can reindex the new dataframe using the `reset_index()` method as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b4d3a",
   "metadata": {},
   "source": [
    "# Writing Out Data to CSV\n",
    "\n",
    "We can use the to_csv command to do export a DataFrame in CSV format. Note that the code below will by default save the data into the current working directory. We can save it to a different folder by adding the foldername and a slash to the file vertical_stack.to_csv('foldername/out.csv'). We use the ‘index=False’ so that pandas doesn’t include the index number for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b252b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f414362",
   "metadata": {},
   "source": [
    "Check out your working directory to make sure the CSV wrote out properly, and that you can open it!   \n",
    "\n",
    "If you want, try to bring it back into Python to make sure it imports properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbf321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For kicks read our output back into Python and make sure all looks good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa89cd",
   "metadata": {},
   "source": [
    "### ✏️ Challenge:\n",
    "In the data folder, there are two survey data files: surveys2001.csv and surveys2002.csv. Your tasks are:\n",
    "\n",
    "1. Read the data into Python \n",
    "2. Combine the files to make one new data frame. \n",
    "3. Create a plot of average plot weight by year grouped by sex. \n",
    "4. Export your results as a CSV \n",
    "5. Make sure it reads back into Python properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21febfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf3910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24c4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a201c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fed487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05961ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d6064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "699a1cdc",
   "metadata": {},
   "source": [
    "# Joining DataFrames\n",
    "\n",
    "When we concatenated our DataFrames we simply added them to each other - stacking them either vertically or side by side. Another way to combine DataFrames is to use columns in each dataset that contain common values (a common unique id). Combining DataFrames using a common field is called “joining”. The columns containing the common values are called “join key(s)”. Joining DataFrames in this way is often useful when one DataFrame is a “lookup table” containing additional data that we want to include in the other.\n",
    "\n",
    "NOTE: This process of joining tables is similar to what we do with tables in an SQL database.\n",
    "\n",
    "For example, the species.csv file that we’ve been working with is a lookup table. This table contains the genus, species and taxa code for 55 species. The species code is unique for each line. These species are identified in our survey data as well using the unique species code. Rather than adding 3 more columns for the genus, species and taxa to each of the 35,549 line Survey data table, we can maintain the shorter table with the species information. When we want to access that information, we can create a query that joins the additional columns of information to the Survey data.\n",
    "\n",
    "Storing data in this way has many benefits including:\n",
    "\n",
    "1. It ensures consistency in the spelling of species attributes (genus, species and taxa) given each species is only entered once. Imagine the possibilities for spelling errors when entering the genus and species thousands of times!\n",
    "2. It also makes it easy for us to make changes to the species information once without having to find each instance of it in the larger survey data.\n",
    "3. It optimizes the size of our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75511b",
   "metadata": {},
   "source": [
    "# Joining Two DataFrames\n",
    "To better understand joins, let’s grab the first 10 lines of our data as a subset to work with. We’ll use the .head method to do this. We’ll also read in a subset of the species table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab in first 10 lines of the surveys table we loaded in earlier (surveys_df)\n",
    "surveys_sub = \n",
    "\n",
    "\n",
    "# Import a small subset of the species data designed for this part of the lesson.\n",
    "# It is stored in the data folder.\n",
    "# Again, use the keywords keep_default_na=False, na_values=[\"\"]\n",
    "species_sub = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08acbc2",
   "metadata": {},
   "source": [
    "In this example, `species_sub` is the lookup table containing genus, species, and taxa names that we want to join with the data in `survey_sub` to produce a new DataFrame that contains all of the columns from both `species_df` and survey_df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc91c18",
   "metadata": {},
   "source": [
    "# Identifying join keys\n",
    "To identify appropriate join keys we first need to know which field(s) are shared between the files (DataFrames). We might inspect both DataFrames to identify these columns. If we are lucky, both DataFrames will have columns with the same name that also contain the same data.   \n",
    "\n",
    "If we are less lucky, we need to identify a (differently-named) column in each DataFrame that contains the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a551e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise species sub columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ff848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View surveys_sub columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66e46e",
   "metadata": {},
   "source": [
    "In our example, the join key is the column containing the two-letter species identifier, which is called species_id.\n",
    "\n",
    "Now that we know the fields with the common species ID attributes in each DataFrame, we are almost ready to join our data. However, since there are [different types of joins](https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/), we also need to decide which type of join makes sense for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf83688",
   "metadata": {},
   "source": [
    "# Inner joins\n",
    "Inner joins\n",
    "\n",
    "The most common type of join is called an inner join. An inner join combines two DataFrames based on a join key and returns a new DataFrame that contains **only** those rows that have matching values in both of the original DataFrames.\n",
    "\n",
    "Inner joins yield a DataFrame that contains only rows where the value being joined exists in BOTH tables. An example of an inner join, adapted from [Jeff Atwood’s blogpost about SQL joins](https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/), is below:\n",
    "\n",
    "![An inner join between two tables](../pictures/inner-join.png \"An inner join between two tables\")\n",
    "\n",
    "The pandas function for performing joins is called `merge` and an Inner join is the default option:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b680db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do an inner merge of \"survey_sub\" and \"species_sub\", store the result to \"merged_inner\"\n",
    "# In this case `species_id` is the only column name in  both dataframes, so if we skipped `left_on`\n",
    "# And `right_on` arguments we would still get the same result\n",
    "merged_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the size of the output data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d48d08",
   "metadata": {},
   "source": [
    "The result of an inner join of `survey_sub` and `species_sub` is a new DataFrame that contains the combined set of columns from `survey_sub` and `species_sub`. It only contains rows that have two-letter species codes that are the same in both the `survey_sub` and `species_sub` DataFrames. In other words, if a row in `survey_sub` has a value of `species_id` that does not appear in the `species_id` column of species, it will not be included in the DataFrame returned by an inner join. Similarly, if a row in `species_sub` has a value of `species_id` that does not appear in the species_id column of `survey_sub`, that row will not be included in the DataFrame returned by an inner join.\n",
    "\n",
    "The two DataFrames that we want to join are passed to the merge function using the left and right argument. The `left_on='species'` argument tells merge to use the `species_id` column as the join key from `survey_sub` (the left DataFrame). Similarly , the `right_on='species_id'` argument tells merge to use the `species_id` column as the join key from `species_sub` (the right DataFrame). For inner joins, the order of the left and right arguments does not matter.\n",
    "\n",
    "The result `merged_inner` DataFrame contains all of the columns from `survey_sub` (record id, month, day, etc.) as well as all the columns from `species_sub` (species_id, genus, species, and taxa).\n",
    "\n",
    "Notice that `merged_inner` has fewer rows than `survey_sub`. This is an indication that there were rows in surveys_df with value(s) for `species_id` that do not exist as value(s) for `species_id` in `species_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437bdf8",
   "metadata": {},
   "source": [
    "# Left joins\n",
    "\n",
    "What if we want to add information from `species_sub` to `survey_sub` without losing any of the information from `survey_sub`? In this case, we use a different type of join called a “left outer join”, or a “left join”.\n",
    "\n",
    "Like an inner join, a left join uses join keys to combine two DataFrames. Unlike an inner join, a `left` join will return all of the rows from the left DataFrame, even those rows whose join key(s) do not have values in the `right` DataFrame. Rows in the `left` DataFrame that are missing values for the join key(s) in the `right` DataFrame will simply have null (i.e., NaN or None) values for those columns in the resulting joined DataFrame.\n",
    "\n",
    "Note: a left join will still discard rows from the `right` DataFrame that do not have values for the join key(s) in the `left` DataFrame.\n",
    "\n",
    "\n",
    "![An left join between two tables](../pictures/left-join.png \"An left join between two tables\")\n",
    "\n",
    "A left join is performed in pandas by calling the same merge function used for inner join, but using the `how='left'` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"merged_left\", a left merge of \"survey_sub\" (left) and \"species_sub\" right\n",
    "\n",
    "# Now check what we've done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a4105",
   "metadata": {},
   "source": [
    "The result DataFrame from a left join (`merged_left`) looks very much like the result DataFrame from an inner join (`merged_inner`) in terms of the columns it contains. However, unlike `merged_inner`, `merged_left` contains the same number of rows as the original `survey_sub` DataFrame. When we inspect `merged_left`, we find there are rows where the information that should have come from `species_sub` (i.e., `species_id`, `genus`, and `taxa`) is missing (they contain NaN values):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7aaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check merged_left where the values of \"genus\" are null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e92f8f",
   "metadata": {},
   "source": [
    "These rows are the ones where the value of `species_id` from `survey_sub` (in this case, PF) does not occur in `species_sub`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dcbdb",
   "metadata": {},
   "source": [
    "Other join types\n",
    "\n",
    "The pandas `merge` function supports two other join types:\n",
    "\n",
    " - Right (outer) join: Invoked by passing `how='right'` as an argument. Similar to a left join, except all rows from the `right` DataFrame are kept, while rows from the `left` DataFrame without matching join key(s) values are discarded.\n",
    " - Full (outer) join: Invoked by passing `how='outer'` as an argument. This join type returns the all pairwise combinations of rows from both DataFrames; i.e., the result DataFrame will be `NaN` where data is missing in one of the dataframes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d4aa3",
   "metadata": {},
   "source": [
    "# 🔥 Final Challenges for this Notebook 🔥\n",
    "## ✏️  Challenge 1. Distributions\n",
    "Create a new DataFrame by joining the contents of the surveys.csv and species.csv tables. Then calculate and plot the distribution of:\n",
    "1. `taxa` by `plot`\n",
    "2. `taxt` by `sex` by `plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f62682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4d796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b20d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f86296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bffd22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0bdb41",
   "metadata": {},
   "source": [
    "## ✏️  Challenge 2. Diversity Index\n",
    "\n",
    "In the data folder, there is a plots.csv file that contains information about the type associated with each plot. \n",
    "\n",
    "1. Use that data to summarize the number of plots by plot type.\n",
    "\n",
    "2. Calculate a diversity index of your choice for control vs rodent exclosure plots. The index should consider both species abundance and number of species. You might choose to use the simple biodiversity index described [here](https://www.amnh.org/learn-teach/curriculum-collections/biodiversity-counts/plant-ecology/how-to-calculate-a-biodiversity-index) which calculates diversity as:\n",
    "\n",
    "        the number of species in the plot / the total number of individuals in the plot = Biodiversity index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95a924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126b34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb2445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37d4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd0d6608",
   "metadata": {},
   "source": [
    "# ❗Key Points\n",
    "\n",
    "\n",
    "- Pandas’ merge and concat can be used to combine subsets of a DataFrame, or even data from different files.\n",
    "\n",
    "- `join` function combines DataFrames based on index or column.\n",
    "\n",
    "- Joining two DataFrames can be done in multiple ways (left, right, and inner) depending on what data must be in the final DataFrame.\n",
    "\n",
    "- `to_csv` can be used to write out DataFrames in CSV format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e683e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
